---
title: "Lecture 1: distance sampling & density surface models"
author: "David L Miller (`@millerdl`)"
output:
  xaringan::moon_reader:
    nature:
      highlightStyle: github
      highlightLines: true
    lib_dir: libs
    seal: false
    mathjax: "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_HTMLorMML"
css: custom.css

---

```{r setup, include=FALSE}
# setup
library(knitr)
library(magrittr)
library(viridis)
opts_chunk$set(cache=TRUE, echo=FALSE, warning=FALSE, error=FALSE,
               message=FALSE, fig.height=8, fig.width=10)

# some useful libraries
library(RColorBrewer)
library(ggplot2)
library(cowplot)
library(sf)
library(rnaturalearth)
theme_set(theme_cowplot(20))

# load the sperm whale data set
load("../data/spermwhale.RData")
```

class: title-slide, inverse, center, middle

# Lecture 1: distance sampling & density surface models

<div style="position: absolute; bottom: 15px; vertical-align: center; left: 10px">
<img src="images/02-foundation-vertical-white.png" height="200">
</div>

---
class: inverse, middle, center
# Why model abundance spatially?

---
class: inverse, middle, center
# Maps

---

.pull-left[
![](images/ak-talk.png)
![](images/bigbears.png)
]

.pull-right[
- Black bears in Alaska
- Heterogeneous spatial distribution

]

---
class: inverse, middle, center
# Spatial decision making

---

.pull-left[
![](images/block_island.png)
![](images/plot-loon-preds.png)
]

.pull-right[
- Block Island, Rhode Island
- First offshore wind in the USA
- Spatial impact assessment

![](images/block-island-windfarms.png)
]

---
class: inverse, middle, center
# A quick tour of distance sampling

---
# How many animals are there? (500!)

```{r, plot, echo=FALSE}
# code adapted from my RDistance book, converged.yt/RDistanceBook
set.seed(1234) # same results every time
library(mgcv) # for inSide

N <- 500
# generate population locations
x <- runif(N)
y <- runif(N)
# plot it
par(mar=rep(0,4))
plot(x,y, pch=19,asp=1,cex=0.4,main="",col="black", axes=FALSE, xlab="", ylab="")
polygon(x=c(0,1,1,0,0), y=c(0,0,1,1,0))
```

---

# Plot sampling

```{r, plotsampling, echo=FALSE}
par(mar=rep(0,4))
plot(x,y, pch=19,asp=1,cex=0.4,main="",col="black", axes=FALSE, xlab="", ylab="")
polygon(x=c(0,1,1,0,0), y=c(0,0,1,1,0))

# generate some quadrats
set.seed(3111)# same results every time
quadrat <- list(x=c(0,0,0.1,0.1,0),y=c(0,0.1,0.1,0,0))
n <- 0
for(i in 1:10){
  # randomly place a quadrat (and plot it)
  this.quadrat <- quadrat
  this.quadrat$x <- this.quadrat$x + runif(1, 0.1, 0.9)
  this.quadrat$y <- this.quadrat$y + runif(1, 0.1, 0.9)
  polygon(this.quadrat, lty=2, border="blue")
  # see which points are inside
  inout <- inSide(this.quadrat, x, y)
  # count them
  n <- n + sum(inout)
  # plot the points inside the quadrat in red
  points(x[inout], y[inout], pch=19, cex=0.6, col="red")
}
```

- Surveyed 10 quadrats (each $0.1^2$ units)
  - Total covered area $a=10 * 0.1^2 =$ `r 10*0.1^2`
- Saw $n=$ `r n` animals
- Estimated density $\hat{D}=n/a=$ `r n/(10*0.1^2)`
- Total area $A=1$
- Estimated abundance $\hat{N}=\hat{D}A=$ `r  n/(10*0.1^2)`

---

# Strip transect

```{r strip}
par(mar=rep(0,4))
plot(x,y, pch=19,asp=1,cex=0.4,main="",col="black", axes=FALSE, xlab="", ylab="")
polygon(x=c(0,1,1,0,0), y=c(0,0,1,1,0))

# zero the count from last time
n <- 0

# generate some strips
set.seed(12)
# in this case we don't randomise the offset of the grid
strip <- list(x=c(-0.0125,-0.0125,0.0125,0.0125,-0.0125), y=c(0,1,1,0,0))
strip$x <- strip$x + 0.1
for(i in 1:4){
  # plot the strip and its centreline
  polygon(strip, lty=2, border="blue")
  lines(rep(mean(range(strip$x)),2), c(0,1), col="blue")
  # see what was inside the strip
  inout <- inSide(strip,x,y)
  # count them
  n <- n + sum(inout)
  # plot those animals within the strip
  points(x[inout], y[inout], pch=19, cex=0.6, col="red")
  # calculate next strip location
  strip$x <- strip$x+0.2
}
# covered area -- same area as for the quadrats
covered <- 4*1*0.025
# estimate density
D <- n/covered
# area of the survey region
A <- 1
# estimate abundance
Nhat <- D*A
```

- Surveyed 4 lines (each $1*0.025$ units)
  - Total covered area $a=4*1*0.025 =$ `r covered`
- Saw $n=$ `r n` animals
- Estimated density $\hat{D}=n/a=$ `r D`
- Total area $A=1$
- Estimated abundance $\hat{N}=\hat{D}A=$ `r  Nhat`

---
# Detectability matters!

- We've assumed certain detection so far
- This rarely happens in the field
- Distance to the **object** is important
- Detectability should decrease with increasing distance

---
# Distance and detectability

<img src="images/dolphins.jpg" alt="Dolphins near and far from the bow of a ship. Credit Scott and Mary Flanders">

<small>Credit <a href="http://www.nordhavn.com/egret/captains_log_sept11.php">Scott and Mary Flanders</a></small>

---
# Line transect

```{r lt}
par(mar=rep(0,4))
plot(x,y, pch=19,asp=1,cex=0.6,main="",col="black", axes=FALSE, xlab="", ylab="")
polygon(x=c(0,1,1,0,0), y=c(0,0,1,1,0))

# generate some lines
# in this case we don't randomise the offset of the grid
lt <- list(x=c(-0.0125, -0.0125, 0.0125, 0.0125, -0.0125),  y=c(0, 1, 1, 0, 0))
# set sigma
sigma <- 0.01
# storage for detected distances
detected_distances <- c()
for(i in 1:5){
  # calculate next strip location
  lt$x <- lt$x+0.15
  # plot the line transect
  lines(x=rep(mean(range(lt$x)),2), y=c(0,1), col="blue",lty=2)
  # calculate the distances to animals from the line
  distances <- abs(lt$x - x)
  # randomly decide which were detected
  detected <- exp(-distances^2/(2*sigma^2)) > runif(length(distances))
  # plot those animals detected
  points(x[detected], y[detected], pch=19, cex=0.6, col="red")
  # collect the distances to detected objects
  detected_distances <- c(detected_distances, distances[detected])
}
```

---
# Line transects - distances

```{r distance-hist}
hist(detected_distances, main="", xlab="Distance",breaks=seq(0,max(detected_distances),len=7))
```
 
- Distances from the **line** (sampler) to animal
- Now we recorded distances, what do they look like?
- "Fold" distribution over, left/right doesn't matter
- Drop-off in # observations w. increasing distance

---
# Distance sampling animation

![Animation of line transect survey](images/distanim.gif)

---
# Detection function

```{r df-fit}
# set truncation
w <- 0.025

hist(detected_distances, main="", xlab="Distance",breaks=seq(0,max(detected_distances),len=7), freq=FALSE, ylim=c(0, 85), axes=FALSE, ylab="Probability of detection")
xx <- seq(0, 0.05, len=1000)

lines(xx, exp(-xx^2/(2*sigma^2))/integrate(function(x)  exp(-x^2/(2*sigma^2)), lower=0, upper=w)$value)
axis(1)

library(Distance)
dd <- ds(detected_distances, truncation=w, adjustment=NULL)

# calculate effective strip width
#mu <- integrate(function(x)  exp(-x^2/(2*sigma^2)), lower=0, upper=w)$value
mu <- predict(dd, esw=TRUE)$fitted[1]
# what is the value of the pdf at zero distance
f0 <- 1/mu

axis(2, at=c(0, f0/2, f0), labels=c(0,0.5,1))

# mark truncation
text(x=0.02, y=f0*0.75, label=paste("truncation w =", w))
abline(v=w, lty=2, lwd=1.5)

```

---
# Distance sampling estimate

```{r calc-Nhat-line, echo=FALSE}
## calculate Nhat

p <- mu/w
n <- length(detected_distances[detected_distances<=w])
covered <- 2*w*5
Nhat.lt <- (A/covered)* (n/p)
```

- Surveyed 5 lines (each area 1 $*$ 2 $*$ `r w`)
  - Total covered area $a=$ 5 $*$ 1 $*$ (2 $*$ `r w`) = `r covered`
- Probability of detection $\hat{p} =$ `r round(p,4)`
- Saw $n=$ `r n` animals
- Inflate to $n/\hat{p}=$ `r round(n/p, 3)`
- Estimated density $\hat{D}=\frac{n/\hat{p}}{a}=$ `r round(n/(covered*p), 1)`
- Total area $A=1$
- Estimated abundance $\hat{N}=\hat{D}A=$ `r  round(Nhat.lt, 1)`

---
# Distance sampling assumptions

1. Animals are distributed independent of lines

2. On the line, detection is certain

3. Distances are recorded correctly

4. Animals don't move before detection


---
# What are detection functions?

- $\mathbb{P}\left( \text{detection } \vert \text{ animal at distance } x \right)$
- (But we want $\mathbb{P}\left( \text{detection } \right)= \hat{p}$)
- "Integrate out distance" == "area under curve" == $\hat{p}$
- Many different forms, depending on the data
- All share some characteristics

```{r df-hn, echo=FALSE, fig.height=3}
par(mfrow=c(1,3))

curve(exp(-x^2/(2*0.01^2)), from=0, to=0.025, xlab="Distance", ylab="Probability of detection", main="Half-normal")

curve(1-exp(-(x/0.005)^(-2.5)), from=0, to=0.025, xlab="Distance", ylab="Probability of detection", main="Hazard-rate")


g <- function(x) exp(-x^2/(2*0.01^2))*(1+0.5*cos((2*pi*x)/0.025))
f <- function(x) g(x)/g(0)
curve(f, from=0, to=0.025, xlab="Distance", ylab="Probability of detection", main="Half-normal with 1 cosine adjustment")
```

---
# Fitting detection functions (in R!)

- Using the package `Distance`
- Function `ds()` does most of the work


```{r echo=TRUE}
library(Distance)
df_hn <- ds(distdata, truncation=6000)
```

<p align="center">More on this in the practical!</p>

---
# Horvitz-Thompson-like estimators

- Once we have $\hat{p}$ how do we get $\hat{N}$?
- Rescale the (flat) density and extrapolate

$$
\hat{N} = \frac{\text{study area}}{\text{covered area}}\sum_{i=1}^n \frac{s_i}{\hat{p}_i}
$$

- $s_i$ are group/cluster sizes
- $\hat{p}_i$ is the detection probability (from detection function)

---
class: inverse, middle, center
# Why spatial modelling?
## Horvitz-Thompson limitations

---
# Hidden in this formula is a simple assumption

- Probability of sampling every point in the study area is equal
- Is this true? Sometimes.
- If (and only if) the design is randomised

$$
\hat{N} = \frac{\text{study area}}{\text{covered area}}\sum_{i=1}^n \frac{s_i}{\hat{p}_i \color{red}{\mathbb{P}(\text{included})}}
$$


---
# Many faces of randomisation

```{r randomisation, fig.width=14, fig.height=4.5, out.width='\\textwidth'}
set.seed(12133)
par(mfrow=c(1,3), cex.main=2.5)

# true random sample
plot(c(0, 1), c(0, 1), type="n", xlab="", ylab="", axes=FALSE, asp=1, main="random placement")
dat <- data.frame(x=runif(10), y=runif(10))
angle <- runif(10, 0, 2*pi)
len <- 0.2
arrows(dat$x, dat$y, dat$x+len*cos(angle), dat$y+len*sin(angle), length=0)
dat <- data.frame(x=runif(10), y=runif(10))
angle <- runif(10, 0, 2*pi)
len <- 0.2
arrows(dat$x, dat$y, dat$x+len*cos(angle), dat$y+len*sin(angle), length=0, col="grey40", lty=2)
box()

# parallel random offset
plot(c(0, 1), c(0, 1), type="n", xlab="", ylab="", axes=FALSE, asp=1, main="random offset parallel lines")
abline(v=seq(0, 1, len=10))
abline(v=seq(0, 1, len=10)+0.07, col="grey40", lty=2)
box()

# random offset zigzag

## make a zigzag
n_segs <- 10
zz <- data.frame(x   = c(seq(0, 0.5, len=n_segs),
                         seq(0.5, 1, len=n_segs)),
                 y   = c(seq(0, 1, len=n_segs),
                         seq(1, 0, len=n_segs)))
# many zigzags
mzz <- rbind(zz,zz,zz)
mzz$x <- mzz$x/3
ind <- 1:nrow(zz)
mzz$x[ind+nrow(zz)] <- mzz$x[ind+nrow(zz)]+1/3
mzz$x[ind+2*nrow(zz)] <- mzz$x[ind+2*nrow(zz)]+2/3

plot(mzz, type="l", xlab="", ylab="", axes=FALSE, asp=1, main="random offset zigzag")
lines(mzz$x+0.06, mzz$y, col="grey40", lty=2)
box()
```

---
# Randomisation & coverage probability

- H-T equation above assumes even coverage
- (Distance for Windows can estimate this)

<img src="images/bc_plan.png" width=35%> <img src="images/bad_coverage.png" width=35% align="right"> 

---
class: inverse, middle, center
# Why spatial modelling?
## Extra spatial information

---

# Extra information

```{r plottracks, echo=FALSE}
# get track shapefile
tracks <- read_sf("../data/transects.shp")

# get a coastline for plotting
usa <- ne_countries(scale=50, type="countries", country="United States of America", returnclass="sf")
usa <- st_crop(usa, st_bbox(tracks) + c(-2, -1, 1, 0.8))

# plot
p_maptr <- ggplot()+
  geom_sf(aes(colour=Survey), data=tracks) + 
  geom_sf(data=usa, colour=NA) +
  coord_sf(expand=FALSE, crs=proj) +
  theme_minimal()
print(p_maptr)
```

```{r save-mapstuff, echo=FALSE}
save(usa, tracks, file="geosave.RData")
```

---
# Extra information - depth

```{r plotdepth}
p <- ggplot() +
  geom_sf(data=usa, colour=NA) +
  geom_tile(aes(x=x, y=y, fill=Depth), data=predgrid) + 
  geom_point(aes(x=x, y=y, size=size), alpha=0.6, data=distdata) +
  coord_sf(expand=FALSE, crs=proj) +
  theme_minimal() +
  scale_fill_viridis_c()
print(p)
```

---
# Extra information - SST

```{r plotsst, fig.width=10}
p <- ggplot() +
  geom_sf(data=usa, colour=NA) +
  geom_tile(aes(x=x, y=y, fill=SST), data=predgrid) + 
  geom_point(aes(x=x, y=y, size=size), alpha=0.6, data=distdata) +
  coord_sf(expand=FALSE, crs=proj) +
  theme_minimal() +
  scale_fill_viridis_c()
print(p)
```

---
class: inverse, middle, center
# Density Surface Modelling overview

---
# Density Surface Modelling flow diagram

<img src="images/dsm-flow.png" alt="DSM process flow diagram" width=100%>


---


# Modelling requirements

- Account for effort
- Flexible/interpretable effects
- Predictions over an arbitrary area
- Include detectability


---
class: inverse, middle, center
# Accounting for effort

---
# Effort

.pull-left[
```{r tracks2, fig.width=10}
print(p_maptr)
```
]

.pull-right[
- Have transects
- Variation in counts and covars along them
- Want a sample unit w/ minimal variation
- "Segments": chunks of effort
]

---
# Chopping up transects

<img src="images/dsmproc.png" alt="Physeter catodon by Noah Schlottman" width=80%>

[Physeter catodon by Noah Schlottman](http://phylopic.org/image/dc76cbdb-dba5-4d8f-8cf3-809515c30dbd/)

---
class: inverse, middle, center
# Flexible, interpretable effects

---
# Smooth response

```{r plotsmooths, messages=FALSE}
library(Distance)
library(dsm)
par(ps=20)
df <- ds(distdata, truncation=6000)
dsm_tw_xy_depth <- dsm(count ~ s(x, y) + s(Depth), ddf.obj=df, observation.data=obs, segment.data=segs, family=tw())
plot(dsm_tw_xy_depth, select=2)
```

---
# Explicit spatial effects

```{r plot-spat-smooths, messages=FALSE}
vis.gam(dsm_tw_xy_depth, view=c("x","y"), plot.type="contour", main="", asp=1, too.far=0.06, n.grid=100)
```

---
class: inverse, middle, center
# Predictions

---
# Predictions over an arbitrary area

.pull-left[

```{r predplot}
predgrid$Nhat <- predict(dsm_tw_xy_depth, predgrid, off.set=predgrid$off.set)
p <- ggplot(predgrid) + 
  geom_sf(data=usa, colour=NA) +
  geom_tile(aes(x=x, y=y, fill=Nhat, width=10*1000, height=10*1000)) +
  labs(fill="Density") +
  coord_sf(expand=FALSE, crs=proj) +
  theme_minimal() +
  scale_fill_viridis_c()
print(p)
```
]

.pull-right[
- Don't want to be restricted to predict on segments
- Predict within survey area
- Extrapolate outside (with caution)
- Working on a grid of cells
]

---
class: inverse, middle, center
# Detection information

---
# Including detection information

- Two options:
  - adjust areas to account for **effective effort**
  - use **Horvitz-Thompson estimates** as response

---
# Count model

- Area of each segment, $A_j$
  - use $A_j\hat{p}_j$
- 💭 effective strip width ( $\hat{\mu} = w\hat{p}$ )
- Response is counts per segment
- "Adjusting for effective effort"

![](images/esw_change.png)

---

# Estimated abundance

- Effort is area of each segment
- Estimate H-T abundance per segment

$$
\hat{n}_j = \sum_i \frac{s_i}{\hat{p}_i}
$$

(where the $i$ observations are in segment $j$)

![](images/Nhat_change.png)

---
# Detectability and covariates

- 2 covariate "levels" in detection function
  - "Observer"/"observation" -- change **within** segment
  - "Segment" -- change **between** segments
- "Count model" only lets us use segment-level covariates
- "Estimated abundance" lets us use either

---
# When to use each approach?

- Generally "nicer" to adjust effort
- Keep response (counts) close to what was observed
- **Unless** you want observation-level covariates

---
class: inverse, middle, center
# Data requirements

---
# What do we need?

- Need to "link" data
  - ✅ Distance data/detection function
  - ✅ Segment data
  - ✅ Observation data (segments 🔗 detections)

---

![](images/dsm_tables.png)

---
class: inverse, middle, center
# Example data

---
# Example data

<img src="images/data_ships.png">

---
# Example data

<img src="images/observers.png">

---
# Sperm whales 

.pull-left[
<img src="images/spermwhale.png" width="100%">
]
.pull-right[

- Hang out near canyons, eat squid
- Surveys in 2004, US east coast
- Thanks to Debi Palka (NOAA NEFSC), Lance Garrison (NOAA SEFSC) for data. Jason Roberts (Duke University) for data prep.
]

---
# Recap

- Model counts or estimated abundance
- The effort is accounted for differently
- Flexible models are good
- Incorporate detectability
- 2 tables + detection function needed